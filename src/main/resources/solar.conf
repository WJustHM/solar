# *************************Spark config
solar.spark.app.name = SOLAR
solar.spark.stream.batchDuration = 1000
solar.spark.driver.cores = 4
solar.spark.driver.maxResultSize = 2g
solar.spark.driver.memory = 1g
solar.spark.task.maxFailures = 1
solar.spark.stream.checkpoint = ./solar
# solar.spark.yarn.am.memory=1g
# solar.spark.driver.memory=1g
# solar.spark.driver.cores=2
# solar.spark.yarn.am.cores=1
# solar.spark.yarn.am.waitTime=100s
# solar.spark.yarn.max.executor.failures=
# solar.spark.executor.cores=1
# solar.spark.executor.instances=2
# solar.spark.yarn.jars=
# solar.spark.jars=
# solar.spark.task.maxFailures=-1
# solar.spark.driver.host=
# solar.spark.driver.port=
solar.spark.executor.memory=2g
solar.spark.executor.cup=4
# solar.spark.rdd.compress=
# solar.spark.streaming.kafka.maxRetries=1
# solar.spark.streaming.kafka.maxRetries=200
# solar.spark.streaming.stopGracefullyOnShutdown=ture

solar.kafka.bootstrap.servers = sunb:9092,suna:9092,sunc:9092
solar.kafka.topics =solar
solar.kafka.key.deserializer = org.apache.kafka.common.serialization.ByteArrayDeserializer
solar.kafka.value.deserializer = org.apache.kafka.common.serialization.ByteArrayDeserializer
solar.kafka.group.id = solar
solar.kakfa.auto.offset.reset = largest
solar.kafka.enable.auto.commit = true


# Merge
merge.illegal.topics =
  merge.normal.topics=
merge.kafka.bootstrap.servers =
merge.kafka.value.serializer = org.apache.kafka.common.serialization.ByteArraySerializer
merge.kafka.key.serializer = org.apache.kafka.common.serialization.ByteArraySerializer
#merge.kafka.acks=all
#merge.kafka.retries=2
#merge.kafka.batch.size=0
#merge.kafka.linger.ms=1
#merge.kafka.partitioner.class= com.wuzhou.producer.PartitionRouter
# merge.kafka.buffer.memory=
# merge.kafka.client.id=
# merge.kafka.compression.type=
# merge.kafka.connections.max.idle.ms=

# merge.kafka.max.block.ms=
# merge.kafka.max.in.flight.requests.per.connection=
# merge.kafka.max.request.size=
# merge.kafka.metadata.max.age.ms=
# merge.kafka.metric.reporters=
# merge.kafka.metrics.num.samples=
# merge.kafka.metrics.sample.window.ms=

# merge.kafka.receive.buffer.bytes=
# merge.kafka.reconnect.backoff.ms=
# merge.kafka.request.timeout.ms=
# merge.kafka.retry.backoff.ms=
# merge.kafka.send.buffer.bytes=



merge.hbase.table.baseinfo = BASEINFO
merge.hbase.table.image = IMAGE

merge.hbase.hbase.zookeeper.quorum = slave-4,slave-5,slave-6
merge.hbase.hbase.zookeeper.property.clientPort = 2181
merge.hbase.hbase.client.write.buffer = 12582912
merge.hbase.hbase.client.max.total.tasks = 500
merge.hbase.hbase.client.max.perserver.tasks = 5
merge.hbase.hbase.client.max.perregion.tasks = 1



# *********************ES config
merge.es.cluster.name=myApp
merge.es.addrees=suna:9300,sunb:9300,sunc:9300
merge.es.index=traffic
merge.es.type=vehicle
#merge.es.resource = ""
#merge.es.resource.write =""
#merge.es.host =
#merge.es.port =
# *********************Mysql config
merge.mysql.driverClass = com.mysql.jdbc.Driver
merge.mysql.username = root
merge.mysql.jdbcUrl = jdbc:mysql://master-1:3306/solar
merge.mysql.password = mysql

merge.redis.cluster=suna:7000,suna:7001,sunb:7000,sunb:7001,sunc:7000,sunc:7001


